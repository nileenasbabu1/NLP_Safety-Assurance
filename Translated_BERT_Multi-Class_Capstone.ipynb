{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Section<a href=\"#Init-Section\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    #Reference\n",
    "    #https://github.com/susanli2016/NLP-with-Python/blob/master/Text_Classification_With_BERT.ipynb\n",
    "\n",
    "In \\[1\\]:\n",
    "\n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow\n",
    "    tensorflow.__version__\n",
    "\n",
    "    # Initialize the random number generator\n",
    "    import random\n",
    "    random.seed(0)\n",
    "\n",
    "    # Ignore the warnings\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    import io\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "    import spacy\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    print(stop_words)\n",
    "\n",
    "    [nltk_data] Downloading package punkt to /root/nltk_data...\n",
    "    [nltk_data]   Unzipping tokenizers/punkt.zip.\n",
    "    [nltk_data] Downloading package stopwords to /root/nltk_data...\n",
    "    [nltk_data]   Unzipping corpora/stopwords.zip.\n",
    "    ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "    Mounted at /content/drive/\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    import os\n",
    "    import sys\n",
    "    os.chdir('/content/drive/My Drive/AI Datasets/')\n",
    "\n",
    "# IMPORT LIBRARIES<a href=\"#IMPORT-LIBRARIES\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    import glob\n",
    "\n",
    "    from sklearn.utils import shuffle\n",
    "    import numpy as np\n",
    "\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.models import Sequential, load_model\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras import backend\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Embedding, LSTM, TimeDistributed, Flatten\n",
    "    from tensorflow.keras import metrics\n",
    "    import tensorflow as tf\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    !pip install transformers==3.0.0\n",
    "\n",
    "    Collecting transformers==3.0.0\n",
    "      Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
    "         |████████████████████████████████| 757kB 11.4MB/s \n",
    "    Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (3.0.12)\n",
    "    Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (1.19.5)\n",
    "    Collecting sentencepiece\n",
    "      Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
    "         |████████████████████████████████| 1.2MB 26.2MB/s \n",
    "    Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (20.8)\n",
    "    Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
    "    Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.8)\n",
    "    Collecting tokenizers==0.8.0-rc4\n",
    "      Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
    "         |████████████████████████████████| 3.0MB 40.1MB/s \n",
    "    Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2.23.0)\n",
    "    Collecting sacremoses\n",
    "      Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
    "         |████████████████████████████████| 890kB 42.4MB/s \n",
    "    Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (4.41.1)\n",
    "    Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n",
    "    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2020.12.5)\n",
    "    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
    "    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
    "    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
    "    Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
    "    Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
    "    Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.0.0)\n",
    "    Building wheels for collected packages: sacremoses\n",
    "      Building wheel for sacremoses (setup.py) ... done\n",
    "      Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e41a27f16e3cc27af93f3289df80aeca16bd7e20e52d871dafc105b08494e8b6\n",
    "      Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
    "    Successfully built sacremoses\n",
    "    Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
    "    Successfully installed sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    import torch\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    from transformers import BertTokenizer\n",
    "    from torch.utils.data import TensorDataset\n",
    "\n",
    "    from transformers import BertForSequenceClassification\n",
    "\n",
    "# BERT models For refence only<a href=\"#BERT-models-For-refence-only\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "    map_name_to_handle = {\n",
    "        'bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "        'bert_en_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "        'bert_multi_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "        'albert_en_base':\n",
    "            'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "        'electra_small':\n",
    "            'https://tfhub.dev/google/electra_small/2',\n",
    "        'electra_base':\n",
    "            'https://tfhub.dev/google/electra_base/2',\n",
    "        'experts_pubmed':\n",
    "            'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "        'experts_wiki_books':\n",
    "            'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "        'talking-heads_base':\n",
    "            'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "    }\n",
    "\n",
    "    map_model_to_preprocess = {\n",
    "        'bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'bert_en_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'bert_multi_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/2',\n",
    "        'albert_en_base':\n",
    "            'https://tfhub.dev/tensorflow/albert_en_preprocess/2',\n",
    "        'electra_small':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'electra_base':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'experts_pubmed':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'experts_wiki_books':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "        'talking-heads_base':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n",
    "    }\n",
    "\n",
    "    tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "    tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "    print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "    print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n",
    "\n",
    "    BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
    "    Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\n",
    "\n",
    "# Load dataset<a href=\"#Load-dataset\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    # Read the data as a data frame\n",
    "\n",
    "    #dataframe = pd.read_csv('dataframe_translated_20210102_2.csv')\n",
    "    dataframe2 = pd.read_csv('dataframe_translated_20210102_2.csv')\n",
    "    dataframe2.head()\n",
    "\n",
    "Out\\[9\\]:\n",
    "\n",
    "|     | index | Short description                                 | Description                                       | Caller            | Assignment group | PP Short description                       | PP Description                                    | Grp No | Language    | Language Code | temp desc                                           | Language 2  | Language Code 2 | English Short description                  | English Description                              | Caller Encoded |\n",
    "|-----|-------|---------------------------------------------------|---------------------------------------------------|-------------------|------------------|--------------------------------------------|---------------------------------------------------|--------|-------------|---------------|-----------------------------------------------------|-------------|-----------------|--------------------------------------------|--------------------------------------------------|----------------|\n",
    "| 0   | 0     | skype error                                       | skype error                                       | owlgqjme qhcozdfx | GRP_0            | skype error                                | skype error                                       | 0      | Latin       | la            | skype error \\|\\| skype error                        | Latin       | la              | skype error                                | skype error                                      | Caller231      |\n",
    "| 1   | 1     | erp_print_tool install.                           | erp_print_tool install.                           | aorthyme rnsuipbk | GRP_0            | erp_print_tool install .                   | erp_print_tool install .                          | 0      | Kinyarwanda | rw            | erp_print_tool install . \\|\\| erp_print_tool ins... | Kinyarwanda | rw              | erp_print_tool install .                   | erp_print_tool install .                         | Caller35       |\n",
    "| 2   | 2     | probleme mit bluescreen .                         | hallo ,\\n\\nes ist erneut passiert. der pc hat ... | vrfpyjwi nzhvgqiw | GRP_24           | probleme mit bluescreen .                  | hallo , es ist erneut passiert . der pc hat si... | 24     | German      | de            | problems with bluescreen. \\|\\| hello, it happene... | English     | en              | problems with bluescreen.                  | hello, it happened again. the pc hung up agai... | Caller284      |\n",
    "| 3   | 3     | reset the password for fygrwuna gomcekzi on e-... | bitte passwort fÃ¼r fygrwuna gomcekzi e-mail z... | fygrwuna gomcekzi | GRP_0            | reset the password for Caller690 on e mail | bitte passwort fa r Caller690 e mail zura ckse... | 0      | German      | de            | reset the password for Caller690 on e mail \\|\\| ... | English     | en              | reset the password for Caller690 on e mail | please reset password for Caller690 e mail, p... | Caller690      |\n",
    "| 4   | 4     | probleme mit laufwerk z: \\laeusvjo fvaihgpx       | probleme mit laufwerk z: \\laeusvjo fvaihgpx       | laeusvjo fvaihgpx | GRP_24           | probleme mit laufwerk z Caller663          | probleme mit laufwerk z Caller663                 | 24     | German      | de            | problems with drive z Caller663 \\|\\| problems wi... | English     | en              | problems with drive z Caller663            | problems with drive z Caller663                  | Caller663      |\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    y_counts = pd.DataFrame(dataframe2['Grp No'].value_counts())\n",
    "    p = y_counts.index.values\n",
    "    y_counts.insert( 0, column=\"new\",value = p)\n",
    "    y_counts.columns = ['Grp No', 'counts']\n",
    "    y_counts['Grp No'].astype(int)\n",
    "    y_counts['counts'].astype(int)\n",
    "    y_counts\n",
    "\n",
    "Out\\[10\\]:\n",
    "\n",
    "|     | Grp No | counts |\n",
    "|-----|--------|--------|\n",
    "| 0   | 0      | 3976   |\n",
    "| 8   | 8      | 661    |\n",
    "| 24  | 24     | 289    |\n",
    "| 12  | 12     | 257    |\n",
    "| 9   | 9      | 252    |\n",
    "| ... | ...    | ...    |\n",
    "| 61  | 61     | 1      |\n",
    "| 67  | 67     | 1      |\n",
    "| 35  | 35     | 1      |\n",
    "| 70  | 70     | 1      |\n",
    "| 73  | 73     | 1      |\n",
    "\n",
    "74 rows × 2 columns\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    y_counts.head(50)\n",
    "\n",
    "Out\\[11\\]:\n",
    "\n",
    "|     | Grp No | counts |\n",
    "|-----|--------|--------|\n",
    "| 0   | 0      | 3976   |\n",
    "| 8   | 8      | 661    |\n",
    "| 24  | 24     | 289    |\n",
    "| 12  | 12     | 257    |\n",
    "| 9   | 9      | 252    |\n",
    "| 2   | 2      | 241    |\n",
    "| 19  | 19     | 215    |\n",
    "| 3   | 3      | 200    |\n",
    "| 6   | 6      | 184    |\n",
    "| 13  | 13     | 145    |\n",
    "| 10  | 10     | 140    |\n",
    "| 5   | 5      | 129    |\n",
    "| 14  | 14     | 118    |\n",
    "| 25  | 25     | 116    |\n",
    "| 33  | 33     | 107    |\n",
    "| 4   | 4      | 100    |\n",
    "| 29  | 29     | 97     |\n",
    "| 18  | 18     | 88     |\n",
    "| 16  | 16     | 85     |\n",
    "| 17  | 17     | 81     |\n",
    "| 31  | 31     | 69     |\n",
    "| 7   | 7      | 68     |\n",
    "| 34  | 34     | 62     |\n",
    "| 26  | 26     | 56     |\n",
    "| 40  | 40     | 45     |\n",
    "| 28  | 28     | 44     |\n",
    "| 41  | 41     | 40     |\n",
    "| 30  | 30     | 39     |\n",
    "| 15  | 15     | 39     |\n",
    "| 42  | 42     | 37     |\n",
    "| 20  | 20     | 36     |\n",
    "| 45  | 45     | 35     |\n",
    "| 22  | 22     | 31     |\n",
    "| 1   | 1      | 31     |\n",
    "| 11  | 11     | 30     |\n",
    "| 21  | 21     | 29     |\n",
    "| 47  | 47     | 27     |\n",
    "| 48  | 48     | 25     |\n",
    "| 23  | 23     | 25     |\n",
    "| 62  | 62     | 25     |\n",
    "| 60  | 60     | 20     |\n",
    "| 39  | 39     | 19     |\n",
    "| 27  | 27     | 18     |\n",
    "| 37  | 37     | 16     |\n",
    "| 36  | 36     | 15     |\n",
    "| 44  | 44     | 15     |\n",
    "| 50  | 50     | 14     |\n",
    "| 65  | 65     | 11     |\n",
    "| 53  | 53     | 11     |\n",
    "| 52  | 52     | 9      |\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    #incidentsData_Group_0 = dataframe2[dataframe2['Assignment group'] == 'GRP_0']\n",
    "    #incidentsData_Others = dataframe2[dataframe2['Assignment group'] != 'GRP_0']\n",
    "    #max_incident_cnt = dataframe2['Assignment group'].value_counts().max()\n",
    "\n",
    "    no_upsampling_grp = ['GRP_0', 'GRP_8', 'GRP_24', 'GRP_12', 'GRP_9']\n",
    "    incidentsData_no_upsample = dataframe2[dataframe2['Assignment group'].isin(no_upsampling_grp)]\n",
    "    incidentsData_Others = dataframe2[~dataframe2['Assignment group'].isin(no_upsampling_grp)]\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    #incidentsData_Others.shape\n",
    "    incidentsData_no_upsample.shape\n",
    "\n",
    "Out\\[13\\]:\n",
    "\n",
    "    (5435, 16)\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    # Treat the imbalance in the 'other' dataset by resampling\n",
    "    from sklearn.utils import resample\n",
    "\n",
    "    incidentsData_upsampled = incidentsData_Others[0:0]\n",
    "\n",
    "    # Upsample minority class\n",
    "    for grp in incidentsData_Others['Assignment group'].unique():\n",
    "        incidentsData_Group = incidentsData_Others[incidentsData_Others['Assignment group'] == grp]\n",
    "        resampled = resample(incidentsData_Group, \n",
    "                             replace=True, # sample with replacement\n",
    "                             #n_samples=int(max_incident_cnt/2), \n",
    "                             n_samples=int(250), \n",
    "                             random_state=123) # reproducible results\n",
    "        \n",
    "        incidentsData_upsampled = incidentsData_upsampled.append(resampled)\n",
    "\n",
    "    incidentsData_Others_upsample = pd.concat([incidentsData_no_upsample,incidentsData_upsampled])\n",
    "    incidentsData_Others_upsample.reset_index(inplace=True)\n",
    "\n",
    "    descending_order = incidentsData_upsampled['Assignment group'].value_counts().sort_values(ascending=False).index\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    from wordcloud import WordCloud, STOPWORDS \n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    flatui = ['#2E82A8','#00A0B8','#00BDB4','#53D69F','#A5EB84','#F9F871']\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    plt.subplots(figsize=(22,5))\n",
    "    #add code to rotate the labels\n",
    "    ax=sns.countplot(x='Assignment group', data=incidentsData_upsampled, palette = sns.color_palette(flatui),order=descending_order)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "![](data:image/png;base64,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%0A)\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    incidentsData_Others_upsample.shape\n",
    "\n",
    "Out\\[17\\]:\n",
    "\n",
    "    (22685, 17)\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    possible_labels = incidentsData_Others_upsample['Assignment group'].unique()\n",
    "\n",
    "    label_dict = {}\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "    label_dict\n",
    "\n",
    "Out\\[18\\]:\n",
    "\n",
    "    {'GRP_0': 0,\n",
    "     'GRP_1': 35,\n",
    "     'GRP_10': 26,\n",
    "     'GRP_11': 22,\n",
    "     'GRP_12': 2,\n",
    "     'GRP_13': 15,\n",
    "     'GRP_14': 17,\n",
    "     'GRP_15': 29,\n",
    "     'GRP_16': 24,\n",
    "     'GRP_17': 40,\n",
    "     'GRP_18': 27,\n",
    "     'GRP_19': 18,\n",
    "     'GRP_2': 8,\n",
    "     'GRP_20': 30,\n",
    "     'GRP_21': 41,\n",
    "     'GRP_22': 42,\n",
    "     'GRP_23': 19,\n",
    "     'GRP_24': 1,\n",
    "     'GRP_25': 6,\n",
    "     'GRP_26': 21,\n",
    "     'GRP_27': 43,\n",
    "     'GRP_28': 5,\n",
    "     'GRP_29': 25,\n",
    "     'GRP_3': 36,\n",
    "     'GRP_30': 14,\n",
    "     'GRP_31': 10,\n",
    "     'GRP_32': 32,\n",
    "     'GRP_33': 7,\n",
    "     'GRP_34': 12,\n",
    "     'GRP_35': 44,\n",
    "     'GRP_36': 9,\n",
    "     'GRP_37': 45,\n",
    "     'GRP_38': 46,\n",
    "     'GRP_39': 47,\n",
    "     'GRP_4': 37,\n",
    "     'GRP_40': 48,\n",
    "     'GRP_41': 49,\n",
    "     'GRP_42': 11,\n",
    "     'GRP_43': 50,\n",
    "     'GRP_44': 51,\n",
    "     'GRP_45': 34,\n",
    "     'GRP_46': 33,\n",
    "     'GRP_47': 52,\n",
    "     'GRP_48': 16,\n",
    "     'GRP_49': 13,\n",
    "     'GRP_5': 28,\n",
    "     'GRP_50': 53,\n",
    "     'GRP_51': 54,\n",
    "     'GRP_52': 31,\n",
    "     'GRP_53': 55,\n",
    "     'GRP_54': 56,\n",
    "     'GRP_55': 57,\n",
    "     'GRP_56': 58,\n",
    "     'GRP_57': 59,\n",
    "     'GRP_58': 60,\n",
    "     'GRP_59': 23,\n",
    "     'GRP_6': 38,\n",
    "     'GRP_60': 61,\n",
    "     'GRP_61': 62,\n",
    "     'GRP_62': 20,\n",
    "     'GRP_63': 63,\n",
    "     'GRP_64': 64,\n",
    "     'GRP_65': 65,\n",
    "     'GRP_66': 66,\n",
    "     'GRP_67': 67,\n",
    "     'GRP_68': 68,\n",
    "     'GRP_69': 69,\n",
    "     'GRP_7': 39,\n",
    "     'GRP_70': 70,\n",
    "     'GRP_71': 71,\n",
    "     'GRP_72': 72,\n",
    "     'GRP_73': 73,\n",
    "     'GRP_8': 3,\n",
    "     'GRP_9': 4}\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "    df = incidentsData_Others_upsample.copy()\n",
    "\n",
    "In \\[20\\]:\n",
    "\n",
    "    df['label'] = df['Assignment group'].replace(label_dict)\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    df.head()\n",
    "\n",
    "Out\\[21\\]:\n",
    "\n",
    "|     | level_0 | index | Short description                                 | Description                                       | Caller            | Assignment group | PP Short description                       | PP Description                                    | Grp No | Language    | Language Code | temp desc                                           | Language 2  | Language Code 2 | English Short description                  | English Description                              | Caller Encoded | label |\n",
    "|-----|---------|-------|---------------------------------------------------|---------------------------------------------------|-------------------|------------------|--------------------------------------------|---------------------------------------------------|--------|-------------|---------------|-----------------------------------------------------|-------------|-----------------|--------------------------------------------|--------------------------------------------------|----------------|-------|\n",
    "| 0   | 0       | 0     | skype error                                       | skype error                                       | owlgqjme qhcozdfx | GRP_0            | skype error                                | skype error                                       | 0      | Latin       | la            | skype error \\|\\| skype error                        | Latin       | la              | skype error                                | skype error                                      | Caller231      | 0     |\n",
    "| 1   | 1       | 1     | erp_print_tool install.                           | erp_print_tool install.                           | aorthyme rnsuipbk | GRP_0            | erp_print_tool install .                   | erp_print_tool install .                          | 0      | Kinyarwanda | rw            | erp_print_tool install . \\|\\| erp_print_tool ins... | Kinyarwanda | rw              | erp_print_tool install .                   | erp_print_tool install .                         | Caller35       | 0     |\n",
    "| 2   | 2       | 2     | probleme mit bluescreen .                         | hallo ,\\n\\nes ist erneut passiert. der pc hat ... | vrfpyjwi nzhvgqiw | GRP_24           | probleme mit bluescreen .                  | hallo , es ist erneut passiert . der pc hat si... | 24     | German      | de            | problems with bluescreen. \\|\\| hello, it happene... | English     | en              | problems with bluescreen.                  | hello, it happened again. the pc hung up agai... | Caller284      | 1     |\n",
    "| 3   | 3       | 3     | reset the password for fygrwuna gomcekzi on e-... | bitte passwort fÃ¼r fygrwuna gomcekzi e-mail z... | fygrwuna gomcekzi | GRP_0            | reset the password for Caller690 on e mail | bitte passwort fa r Caller690 e mail zura ckse... | 0      | German      | de            | reset the password for Caller690 on e mail \\|\\| ... | English     | en              | reset the password for Caller690 on e mail | please reset password for Caller690 e mail, p... | Caller690      | 0     |\n",
    "| 4   | 4       | 4     | probleme mit laufwerk z: \\laeusvjo fvaihgpx       | probleme mit laufwerk z: \\laeusvjo fvaihgpx       | laeusvjo fvaihgpx | GRP_24           | probleme mit laufwerk z Caller663          | probleme mit laufwerk z Caller663                 | 24     | German      | de            | problems with drive z Caller663 \\|\\| problems wi... | English     | en              | problems with drive z Caller663            | problems with drive z Caller663                  | Caller663      | 1     |\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                      df.label.values, \n",
    "                                                      test_size=0.15, \n",
    "                                                      random_state=42, \n",
    "                                                      stratify=df.label.values)\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "    df.loc[X_train, 'data_type'] = 'train'\n",
    "    df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "In \\[24\\]:\n",
    "\n",
    "    df.groupby(['Assignment group', 'label', 'data_type']).count()\n",
    "\n",
    "Out\\[24\\]:\n",
    "\n",
    "|                  |       |           | level_0 | index | Short description | Description | Caller | PP Short description | PP Description | Grp No | Language | Language Code | temp desc | Language 2 | Language Code 2 | English Short description | English Description | Caller Encoded |\n",
    "|------------------|-------|-----------|---------|-------|-------------------|-------------|--------|----------------------|----------------|--------|----------|---------------|-----------|------------|-----------------|---------------------------|---------------------|----------------|\n",
    "| Assignment group | label | data_type |         |       |                   |             |        |                      |                |        |          |               |           |            |                 |                           |                     |                |\n",
    "| GRP_0            | 0     | train     | 3380    | 3380  | 3380              | 3380        | 3380   | 3380                 | 3378           | 3380   | 3380     | 3380          | 3380      | 3380       | 3380            | 3380                      | 3380                | 3380           |\n",
    "|                  |       | val       | 596     | 596   | 596               | 596         | 596    | 596                  | 596            | 596    | 596      | 596           | 596       | 596        | 596             | 596                       | 596                 | 596            |\n",
    "| GRP_1            | 35    | train     | 213     | 213   | 213               | 213         | 213    | 213                  | 213            | 213    | 213      | 213           | 213       | 213        | 213             | 213                       | 213                 | 213            |\n",
    "|                  |       | val       | 37      | 37    | 37                | 37          | 37     | 37                   | 37             | 37     | 37       | 37            | 37        | 37         | 37              | 37                        | 37                  | 37             |\n",
    "| GRP_10           | 26    | train     | 212     | 212   | 212               | 212         | 212    | 212                  | 212            | 212    | 212      | 212           | 212       | 212        | 212             | 212                       | 212                 | 212            |\n",
    "| ...              | ...   | ...       | ...     | ...   | ...               | ...         | ...    | ...                  | ...            | ...    | ...      | ...           | ...       | ...        | ...             | ...                       | ...                 | ...            |\n",
    "| GRP_73           | 73    | val       | 37      | 37    | 37                | 37          | 37     | 37                   | 37             | 37     | 37       | 37            | 37        | 37         | 37              | 37                        | 37                  | 37             |\n",
    "| GRP_8            | 3     | train     | 562     | 562   | 562               | 562         | 562    | 562                  | 562            | 562    | 562      | 562           | 562       | 562        | 562             | 562                       | 562                 | 562            |\n",
    "|                  |       | val       | 99      | 99    | 99                | 99          | 99     | 99                   | 99             | 99     | 99       | 99            | 99        | 99         | 99              | 99                        | 99                  | 99             |\n",
    "| GRP_9            | 4     | train     | 214     | 214   | 214               | 214         | 214    | 214                  | 214            | 214    | 214      | 214           | 214       | 214        | 214             | 214                       | 214                 | 214            |\n",
    "|                  |       | val       | 38      | 38    | 38                | 38          | 38     | 38                   | 38             | 38     | 38       | 38            | 38        | 38         | 38              | 38                        | 38                  | 38             |\n",
    "\n",
    "148 rows × 16 columns\n",
    "\n",
    "In \\[25\\]:\n",
    "\n",
    "    df['CallerCED'] = df['Caller Encoded'] + ' . ' + df['English Short description'] + ' . ' + df['English Description']\n",
    "\n",
    "In \\[26\\]:\n",
    "\n",
    "    #df.head(5)\n",
    "    df.shape\n",
    "\n",
    "Out\\[26\\]:\n",
    "\n",
    "    (22685, 20)\n",
    "\n",
    "In \\[27\\]:\n",
    "\n",
    "    fig = plt.figure(figsize=(6,9))\n",
    "    text_len=df['CallerCED'].str.split().map(lambda x: len(str(x).split(\" \")))\n",
    "    sns.displot(text_len.dropna(),color='#00A0B8',binwidth=25)\n",
    "    fig.suptitle('Words in description')\n",
    "    plt.show()\n",
    "\n",
    "    <Figure size 432x648 with 0 Axes>\n",
    "\n",
    "![](data:image/png;base64,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%0A)\n",
    "\n",
    "In \\[28\\]:\n",
    "\n",
    "    text_len\n",
    "\n",
    "Out\\[28\\]:\n",
    "\n",
    "    0         7\n",
    "    1         9\n",
    "    2        33\n",
    "    3        27\n",
    "    4        13\n",
    "             ..\n",
    "    22680    17\n",
    "    22681    17\n",
    "    22682    17\n",
    "    22683    17\n",
    "    22684    17\n",
    "    Name: CallerCED, Length: 22685, dtype: int64\n",
    "\n",
    "# BERT - Define Bert Tokenizer, Model def<a href=\"#BERT---Define-Bert-Tokenizer,-Model-def\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Prep input data tensors, define BERT model for multi class\n",
    "classification useing pre-trained model from Huggingface BERT\n",
    "\n",
    "In \\[29\\]:\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                              do_lower_case=True)\n",
    "\n",
    "In \\[30\\]:\n",
    "\n",
    "    encoded_data_train = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type=='train'].CallerCED.values, \n",
    "        add_special_tokens=True, \n",
    "        return_attention_mask=True, \n",
    "        pad_to_max_length=True, \n",
    "        #max_length=256, \n",
    "        max_length=128,\n",
    "        #max_length=50, \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type=='val'].CallerCED.values, \n",
    "        add_special_tokens=True, \n",
    "        return_attention_mask=True, \n",
    "        pad_to_max_length=True, \n",
    "        #max_length=256,\n",
    "        max_length=128,\n",
    "        #max_length=50, \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "    Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'only_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you may want to check this is the right behavior.\n",
    "    Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'only_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you may want to check this is the right behavior.\n",
    "\n",
    "In \\[31\\]:\n",
    "\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "In \\[32\\]:\n",
    "\n",
    "    len(dataset_train), len(dataset_val)\n",
    "\n",
    "Out\\[32\\]:\n",
    "\n",
    "    (19282, 3403)\n",
    "\n",
    "In \\[33\\]:\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                          num_labels=len(label_dict),\n",
    "                                                          output_attentions=False,\n",
    "                                                          output_hidden_states=False)\n",
    "\n",
    "    Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
    "    - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
    "    - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
    "    Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
    "    You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "\n",
    "In \\[34\\]:\n",
    "\n",
    "    from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "    batch_size = 3\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, \n",
    "                                  sampler=RandomSampler(dataset_train), \n",
    "                                  batch_size=batch_size)\n",
    "\n",
    "    dataloader_validation = DataLoader(dataset_val, \n",
    "                                       sampler=SequentialSampler(dataset_val), \n",
    "                                       batch_size=batch_size)\n",
    "\n",
    "In \\[35\\]:\n",
    "\n",
    "    from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr=1e-5, \n",
    "                      eps=1e-8)\n",
    "\n",
    "In \\[36\\]:\n",
    "\n",
    "    epochs = 5\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=len(dataloader_train)*epochs)\n",
    "\n",
    "In \\[37\\]:\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    def flat_accuracy(preds, labels):\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "    def accuracy(preds, labels):\n",
    "        outputs = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        return np.sum(outputs == labels_flat)\n",
    "\n",
    "    def f1_score_func(preds, labels):\n",
    "        preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "    def accuracy_per_class(preds, labels):\n",
    "        label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "        \n",
    "        preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "\n",
    "        for label in np.unique(labels_flat):\n",
    "            y_preds = preds_flat[labels_flat==label]\n",
    "            y_true = labels_flat[labels_flat==label]\n",
    "            print(f'Class: {label_dict_inverse[label]}')\n",
    "            print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "In \\[38\\]:\n",
    "\n",
    "    import random\n",
    "\n",
    "    seed_val = 17\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "In \\[39\\]:\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    cuda\n",
    "\n",
    "In \\[40\\]:\n",
    "\n",
    "    def evaluate(dataloader_val):\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        loss_val_total = 0\n",
    "        predictions, true_vals = [], []\n",
    "        total_eval_accuracy = 0\n",
    "        \n",
    "        for batch in dataloader_val:\n",
    "            \n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[2],\n",
    "                     }\n",
    "\n",
    "            with torch.no_grad():        \n",
    "                outputs = model(**inputs)\n",
    "                \n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss_val_total += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = inputs['labels'].cpu().numpy()\n",
    "            predictions.append(logits)\n",
    "            true_vals.append(label_ids)\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "        \n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = total_eval_accuracy / len(dataloader_val)\n",
    "      \n",
    "                \n",
    "        return loss_val_avg, predictions, true_vals, avg_val_accuracy\n",
    "                \n",
    "      \n",
    "\n",
    "In \\[41\\]:\n",
    "\n",
    "        #import torch\n",
    "        #torch.cuda.empty_cache()\n",
    "\n",
    "# Checkpoint - retrain from previously saved model - Run only needed<a\n",
    "href=\"#Checkpoint---retrain-from-previously-saved-model---Run-only-needed\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[42\\]:\n",
    "\n",
    "    model.load_state_dict(torch.load('trans_finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "\n",
    "Out\\[42\\]:\n",
    "\n",
    "    <All keys matched successfully>\n",
    "\n",
    "In \\[43\\]:\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    cuda\n",
    "\n",
    "# BERT Training<a href=\"#BERT-Training\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[44\\]:\n",
    "\n",
    "    epochs = 4\n",
    "    #epochs = 5\n",
    "\n",
    "In \\[45\\]:\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "\n",
    "            model.zero_grad()\n",
    "            \n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[2],\n",
    "                     }       \n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "             \n",
    "            \n",
    "        #torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n",
    "        torch.save(model.state_dict(), 'trans_finetuned_BERT_epoch_{}.model'.format(epoch))\n",
    "\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "        \n",
    "        loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "        \n",
    "        val_loss, predictions, true_vals, avg_val_accuracy = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        tqdm.write(f'Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "    Epoch 1\n",
    "    Training loss: 1.9737895815569488\n",
    "    Validation loss: 1.683176345606273\n",
    "    F1 Score (Weighted): 0.5186377253060208\n",
    "    Accuracy: 0.5832599118942728\n",
    "\n",
    "    Epoch 2\n",
    "    Training loss: 1.5288649716082143\n",
    "    Validation loss: 1.4281004422889931\n",
    "    F1 Score (Weighted): 0.6025144951810212\n",
    "    Accuracy: 0.6452276064610856\n",
    "\n",
    "    Epoch 3\n",
    "    Training loss: 1.3024044535109047\n",
    "    Validation loss: 1.3321846467555636\n",
    "    F1 Score (Weighted): 0.6286957644037092\n",
    "    Accuracy: 0.6622613803230532\n",
    "\n",
    "    Epoch 4\n",
    "    Training loss: 1.175246476938\n",
    "    Validation loss: 1.2695162046735589\n",
    "    F1 Score (Weighted): 0.6482699969718998\n",
    "    Accuracy: 0.6787077826725394\n",
    "\n",
    "# Run only if GPU memory error above section. Manual Training<a href=\"#Run-only-if-GPU-memory--error-above-section.-Manual-Training\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Run outside the epochs iteration only if needed\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "        val_loss, predictions, true_vals, avg_val_accuracy = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        tqdm.write(f'Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "    Validation loss: 0.9904041105922361\n",
    "    F1 Score (Weighted): 0.7650140247295772\n",
    "    Accuracy: 0.7964757709251095\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # upload external file before import\n",
    "    #from google.colab import files\n",
    "    #files.upload()\n",
    "    #import helper\n",
    "\n",
    "    #files.upload()\n",
    "    #import fc_model\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    #epoch 1 \n",
    "    #torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "\n",
    "    # download checkpoint file\n",
    "    #files.download('checkpoint.pth')\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    #torch.save(model.state_dict(), 'finetuned_BERT_epoch_{epoch}.model')\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "        \n",
    "        torch.save(model.state_dict(), 'finetuned_BERT_epoch_{epoch1}.model')\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "        \n",
    "        loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "        \n",
    "        val_loss, predictions, true_vals, avg_val_accuracy  = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        tqdm.write(f'Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "    Epoch 1\n",
    "    Training loss: 0.4689319437316262\n",
    "    Validation loss: 0.07559893933844199\n",
    "    F1 Score (Weighted): 0.9885210834945934\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # epoch 2 manual run\n",
    "    for epoch in tqdm(range(2, 3)):\n",
    "        model.train()\n",
    "        \n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "\n",
    "            model.zero_grad()\n",
    "            \n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[2],\n",
    "                     }       \n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "             \n",
    "            \n",
    "        #torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n",
    "        torch.save(model.state_dict(), 'finetuned_BERT_epoch_{}.model'.format(epoch))\n",
    "\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "        \n",
    "        loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "        \n",
    "        val_loss, predictions, true_vals, avg_val_accuracy  = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        tqdm.write(f'Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    #epoch 2 \n",
    "    torch.save(model.state_dict(), 'checkpoint2.pth')\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    epoch = 2\n",
    "    print('finetuned_BERT_epoch_{}.model'.format(epoch))\n",
    "\n",
    "    finetuned_BERT_epoch_2.model\n",
    "\n",
    "# Load the previously SAVED MODEL (Choose file here)<a href=\"#Load-the-previously-SAVED-MODEL-(Choose-file-here)\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "file for new prediction/ evaluation\n",
    "\n",
    "In \\[46\\]:\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                          num_labels=len(label_dict),\n",
    "                                                          output_attentions=False,\n",
    "                                                          output_hidden_states=False)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
    "    - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
    "    - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
    "    Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
    "    You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "\n",
    "Out\\[46\\]:\n",
    "\n",
    "    BertForSequenceClassification(\n",
    "      (bert): BertModel(\n",
    "        (embeddings): BertEmbeddings(\n",
    "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "          (position_embeddings): Embedding(512, 768)\n",
    "          (token_type_embeddings): Embedding(2, 768)\n",
    "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "          (dropout): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "        (encoder): BertEncoder(\n",
    "          (layer): ModuleList(\n",
    "            (0): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (1): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (2): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (3): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (4): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (5): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (6): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (7): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (8): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (9): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (10): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "            (11): BertLayer(\n",
    "              (attention): BertAttention(\n",
    "                (self): BertSelfAttention(\n",
    "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "                (output): BertSelfOutput(\n",
    "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                  (dropout): Dropout(p=0.1, inplace=False)\n",
    "                )\n",
    "              )\n",
    "              (intermediate): BertIntermediate(\n",
    "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "              )\n",
    "              (output): BertOutput(\n",
    "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "                (dropout): Dropout(p=0.1, inplace=False)\n",
    "              )\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (pooler): BertPooler(\n",
    "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "          (activation): Tanh()\n",
    "        )\n",
    "      )\n",
    "      (dropout): Dropout(p=0.1, inplace=False)\n",
    "      (classifier): Linear(in_features=768, out_features=74, bias=True)\n",
    "    )\n",
    "\n",
    "In \\[47\\]:\n",
    "\n",
    "    #model.load_state_dict(torch.load('data_volume/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "    model.load_state_dict(torch.load('trans_finetuned_BERT_epoch_4.model', map_location=torch.device('cpu')))\n",
    "\n",
    "Out\\[47\\]:\n",
    "\n",
    "    <All keys matched successfully>\n",
    "\n",
    "In \\[48\\]:\n",
    "\n",
    "    avg_val_loss, predictions, true_vals, avg_val_accuracy  = evaluate(dataloader_validation)\n",
    "\n",
    "In \\[49\\]:\n",
    "\n",
    "    accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "    Class: GRP_0\n",
    "    Accuracy: 417/596\n",
    "\n",
    "    Class: GRP_24\n",
    "    Accuracy: 29/43\n",
    "\n",
    "    Class: GRP_12\n",
    "    Accuracy: 0/39\n",
    "\n",
    "    Class: GRP_8\n",
    "    Accuracy: 51/99\n",
    "\n",
    "    Class: GRP_9\n",
    "    Accuracy: 0/38\n",
    "\n",
    "    Class: GRP_28\n",
    "    Accuracy: 34/37\n",
    "\n",
    "    Class: GRP_25\n",
    "    Accuracy: 12/38\n",
    "\n",
    "    Class: GRP_33\n",
    "    Accuracy: 23/38\n",
    "\n",
    "    Class: GRP_2\n",
    "    Accuracy: 1/38\n",
    "\n",
    "    Class: GRP_36\n",
    "    Accuracy: 34/37\n",
    "\n",
    "    Class: GRP_31\n",
    "    Accuracy: 35/37\n",
    "\n",
    "    Class: GRP_42\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_34\n",
    "    Accuracy: 18/37\n",
    "\n",
    "    Class: GRP_49\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_30\n",
    "    Accuracy: 31/37\n",
    "\n",
    "    Class: GRP_13\n",
    "    Accuracy: 9/37\n",
    "\n",
    "    Class: GRP_48\n",
    "    Accuracy: 34/38\n",
    "\n",
    "    Class: GRP_14\n",
    "    Accuracy: 5/37\n",
    "\n",
    "    Class: GRP_19\n",
    "    Accuracy: 0/38\n",
    "\n",
    "    Class: GRP_23\n",
    "    Accuracy: 35/38\n",
    "\n",
    "    Class: GRP_62\n",
    "    Accuracy: 26/38\n",
    "\n",
    "    Class: GRP_26\n",
    "    Accuracy: 12/37\n",
    "\n",
    "    Class: GRP_11\n",
    "    Accuracy: 36/38\n",
    "\n",
    "    Class: GRP_59\n",
    "    Accuracy: 34/37\n",
    "\n",
    "    Class: GRP_16\n",
    "    Accuracy: 15/37\n",
    "\n",
    "    Class: GRP_29\n",
    "    Accuracy: 21/38\n",
    "\n",
    "    Class: GRP_10\n",
    "    Accuracy: 1/38\n",
    "\n",
    "    Class: GRP_18\n",
    "    Accuracy: 12/37\n",
    "\n",
    "    Class: GRP_5\n",
    "    Accuracy: 0/38\n",
    "\n",
    "    Class: GRP_15\n",
    "    Accuracy: 29/38\n",
    "\n",
    "    Class: GRP_20\n",
    "    Accuracy: 23/37\n",
    "\n",
    "    Class: GRP_52\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_32\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_46\n",
    "    Accuracy: 37/37\n",
    "\n",
    "    Class: GRP_45\n",
    "    Accuracy: 21/38\n",
    "\n",
    "    Class: GRP_1\n",
    "    Accuracy: 13/37\n",
    "\n",
    "    Class: GRP_3\n",
    "    Accuracy: 4/37\n",
    "\n",
    "    Class: GRP_4\n",
    "    Accuracy: 8/38\n",
    "\n",
    "    Class: GRP_6\n",
    "    Accuracy: 0/37\n",
    "\n",
    "    Class: GRP_7\n",
    "    Accuracy: 25/37\n",
    "\n",
    "    Class: GRP_17\n",
    "    Accuracy: 20/37\n",
    "\n",
    "    Class: GRP_21\n",
    "    Accuracy: 31/38\n",
    "\n",
    "    Class: GRP_22\n",
    "    Accuracy: 26/38\n",
    "\n",
    "    Class: GRP_27\n",
    "    Accuracy: 33/37\n",
    "\n",
    "    Class: GRP_35\n",
    "    Accuracy: 37/37\n",
    "\n",
    "    Class: GRP_37\n",
    "    Accuracy: 33/37\n",
    "\n",
    "    Class: GRP_38\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_39\n",
    "    Accuracy: 29/37\n",
    "\n",
    "    Class: GRP_40\n",
    "    Accuracy: 25/38\n",
    "\n",
    "    Class: GRP_41\n",
    "    Accuracy: 32/37\n",
    "\n",
    "    Class: GRP_43\n",
    "    Accuracy: 37/37\n",
    "\n",
    "    Class: GRP_44\n",
    "    Accuracy: 31/37\n",
    "\n",
    "    Class: GRP_47\n",
    "    Accuracy: 23/37\n",
    "\n",
    "    Class: GRP_50\n",
    "    Accuracy: 33/38\n",
    "\n",
    "    Class: GRP_51\n",
    "    Accuracy: 35/38\n",
    "\n",
    "    Class: GRP_53\n",
    "    Accuracy: 22/37\n",
    "\n",
    "    Class: GRP_54\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_55\n",
    "    Accuracy: 32/38\n",
    "\n",
    "    Class: GRP_56\n",
    "    Accuracy: 28/37\n",
    "\n",
    "    Class: GRP_57\n",
    "    Accuracy: 20/38\n",
    "\n",
    "    Class: GRP_58\n",
    "    Accuracy: 37/37\n",
    "\n",
    "    Class: GRP_60\n",
    "    Accuracy: 0/37\n",
    "\n",
    "    Class: GRP_61\n",
    "    Accuracy: 37/37\n",
    "\n",
    "    Class: GRP_63\n",
    "    Accuracy: 23/38\n",
    "\n",
    "    Class: GRP_64\n",
    "    Accuracy: 37/37\n",
    "\n",
    "    Class: GRP_65\n",
    "    Accuracy: 33/38\n",
    "\n",
    "    Class: GRP_66\n",
    "    Accuracy: 37/37\n",
    "\n",
    "    Class: GRP_67\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_68\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_69\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_70\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_71\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_72\n",
    "    Accuracy: 38/38\n",
    "\n",
    "    Class: GRP_73\n",
    "    Accuracy: 37/37\n",
    "\n",
    "In \\[50\\]:\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "      Accuracy: 0.68\n",
    "      Validation Loss: 1.27"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
